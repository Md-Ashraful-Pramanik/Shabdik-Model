{"cells":[{"cell_type":"markdown","metadata":{"id":"_DcSJ9kr1fI6"},"source":["# Char-Level model without using input embedding."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24970,"status":"ok","timestamp":1642064376060,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"Xo02O1JtJU5g","outputId":"dd324fe2-aa2d-4af9-858e-588a2b000aa8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5423,"status":"ok","timestamp":1642064381479,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"G4ASKc-qyIbF","outputId":"69b530d4-b778-4610-b2ff-2ba67973ecdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 35.2 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.15.0\n"]}],"source":["!pip install tensorflow-addons\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time\n","import pickle\n","import numpy as np\n","import urllib3\n","import shutil\n","import zipfile\n","import itertools"]},{"cell_type":"markdown","metadata":{"id":"Udq3BXq10NhZ"},"source":["### Download File"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-fvT1cC0Qsd"},"outputs":[],"source":["colab_base = '/content/drive/MyDrive/ashraful/'\n","pc_base = './'\n","base = colab_base\n","\n","google_dataset_path = base + 'dataset/google-dataset.txt'\n","modified_google_dataset_path = base + 'dataset/modified-google-dataset.txt'\n","phoneme_dataset = base + 'dataset/phoneme-dataset.txt'\n","my_dataset_path = base + 'dataset/my-dataset.txt'\n","new_dataset_path = base + 'dataset/new/dataset-new.txt'\n","top20k_path = base + 'dataset/new/top20k-3.txt'\n","\n","top_50k_word_file = base + 'dataset/new/top50k-sentiment.txt'\n","top_20k_word_file = base + 'dataset/new/top20k-sentiment.txt'\n","\n","input_tokenizer_retrieve = base + 'dataset/new/input-tokenizer.pickle'\n","target_tokenizer_retrieve = base + 'dataset/new/target-tokenizer.pickle'\n","target_word_tokenizer_retrieve = base + 'dataset/new/target-tokenizer-word.pickle'\n","\n","word_frequency_dict_file = base + '/dataset/new/word_frequency_dictionary.pickle'\n","word_frequency_dict_log_file = base + '/dataset/new/word_frequency_dictionary-log.pickle'\n","word_frequency_dict_sqrt_file = base + '/dataset/new/word_frequency_dictionary-sqrt.pickle'\n","\n","# dataset_paths = [new_dataset_path, top_50k_word_file, top20k_path, top20k_path]\n","dataset_paths = [new_dataset_path]\n","\n","splitted_data_path = base + 'dataset/splited-my-data-lstm'\n","\n","checkpoint_dir = base + 'models/LSTM/char-level-model'\n","model_weights_path = base + 'models/LSTM/char-level-model-2/weights'\n","# w-weights-2 => 47.50\n","progress_file_path = base + 'models/LSTM/progress.txt'\n","\n","\n","input_tokenizer_dir = base + 'models/LSTM/input-tokenizer.pickle'\n","target_tokenizer_dir = base + 'models/LSTM/target-tokenizer.pickle'\n","example_batch_dir = base + 'models/LSTM/example_batch.pickle'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4715,"status":"ok","timestamp":1642064387425,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"vIwO_vlG7ixY","outputId":"5d863ef2-b0d4-4980-8e90-3a2443b3527b"},"outputs":[{"data":{"text/plain":["1483.176439783953"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["try:\n","    with open(word_frequency_dict_sqrt_file, mode='rb') as corpus:\n","        word_frequency_dict = pickle.loads(corpus.read())\n","except:\n","    print(\"Can not open file\")\n","\n","word_frequency_dict[\"থেকে\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imc3M7Wb9BQj"},"outputs":[],"source":["class Dataset:\n","    def __init__(self):\n","        self.inp_lang_tokenizer = None\n","        self.targ_lang_tokenizer = None\n","        self.train_dataset = None\n","        self.val_dataset = None\n","\n","    def create_dataset(self):\n","        # num_examples : Limit the total number of training example for faster training (set num_examples = len(lines) to use full data)\n","        lines = list()\n","\n","        for path in dataset_paths:\n","            lines.extend(io.open(path, encoding='UTF-8').read().strip().split('\\n'))\n","        \n","        # lines = list(lines)\n","        lines.sort()\n","        print(len(lines))\n","\n","        word_pairs = [[[char for char in '<' + w.replace('ঃ\\n', '').replace('\\n', '') + '>'] for w in l.split(',')] for l in lines]\n","\n","        print(word_pairs[0][0])\n","        print(word_pairs[0][1])\n","\n","        return zip(*word_pairs)\n","\n","    # Step 3 and Step 4\n","    def tokenize(self, lang, lang_tokenizer=None, maxlen=20):\n","        if lang_tokenizer is None:\n","            lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n","            lang_tokenizer.fit_on_texts(lang)\n","        \n","        tensor = lang_tokenizer.texts_to_sequences(lang)\n","        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',\n","                                                               maxlen=maxlen, truncating='post')\n","\n","        return tensor, lang_tokenizer\n","\n","    def load_dataset(self):\n","        # creating cleaned input, output pairs\n","        self.retrieve_tokenizer()\n","        inp_lang, targ_lang = self.create_dataset()\n","\n","        input_tensor, inp_lang_tokenizer = self.tokenize(inp_lang, self.inp_lang_tokenizer)\n","        target_tensor, targ_lang_tokenizer = self.tokenize(targ_lang, self.targ_lang_tokenizer)\n","\n","        return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer\n","\n","    def save_data(self):\n","        data = tf.constant([self.inp_lang_tokenizer, self.targ_lang_tokenizer, \\\n","            self.train_dataset, self.val_dataset])\n","\n","        with open(splitted_data_path, mode='wb') as data_file:\n","            pickle.dump(data, data_file, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    def retrieve_data(self):\n","        try:\n","            1/0\n","            with open(splitted_data_path, mode='rb') as data_file:\n","                data = pickle.load(data_file)\n","                [self.inp_lang_tokenizer, self.targ_lang_tokenizer, \\\n","                    self.train_dataset, self.val_dataset] = data.numpy()\n","        except:\n","            print(\"Not found\")\n","            return False\n","\n","        return True\n","\n","    def retrieve_tokenizer(self):\n","        \n","        try:\n","            with open(input_tokenizer_retrieve, mode='rb') as data_file:\n","                self.inp_lang_tokenizer = pickle.load(data_file)\n","            \n","        except:\n","            print(\"Not found jhkhk\")\n","            return False\n","\n","        try:\n","            with open(target_tokenizer_retrieve, mode='rb') as data_file:\n","                self.targ_lang_tokenizer = pickle.load(data_file)\n","            \n","        except:\n","            print(\"Not found jgxghkjgkgjkjkjhk\")\n","            return False\n","\n","        # print(len(inp_lang_tokenizer.word_index))\n","        # print(len(targ_lang_tokenizer.word_index))\n","        return True\n","\n","    def call(self, BATCH_SIZE):\n","        # if self.retrieve_data() == False:\n","        input_tensor, target_tensor, self.inp_lang_tokenizer, self.targ_lang_tokenizer = \\\n","            self.load_dataset()\n","\n","        print(\"Input tensor\", input_tensor.shape)\n","        print(\"Output tensor\", target_tensor.shape)\n","\n","        input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = \\\n","            train_test_split(input_tensor, target_tensor, test_size=0.2, random_state=4651)\n","\n","        print(input_tensor_train.shape, target_tensor_train.shape)\n","        print(input_tensor_train[500])\n","        print(input_tensor_val[500])\n","\n","        BUFFER_SIZE = len(input_tensor_train)\n","        self.train_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train))\n","        self.train_dataset = self.train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","\n","        self.val_dataset = tf.data.Dataset.from_tensor_slices((input_tensor_val, target_tensor_val))\n","        self.val_dataset = self.val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n","\n","        return self.inp_lang_tokenizer, self.targ_lang_tokenizer, self.train_dataset, self.val_dataset"]},{"cell_type":"markdown","metadata":{"id":"TOGq0hRk9tad"},"source":["### Create Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78719,"status":"ok","timestamp":1642064466124,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"oPv0BItC9wEz","outputId":"caed04a8-1e0c-48f6-9e05-4ef42c9af456"},"outputs":[{"name":"stdout","output_type":"stream","text":["2402977\n","['<', 'a', '>']\n","['<', 'অ', '>']\n","Input tensor (2402977, 20)\n","Output tensor (2402977, 20)\n","(1922381, 20) (1922381, 20)\n","[ 1 20  5  8  7 14  7  2  0  0  0  0  0  0  0  0  0  0  0  0]\n","[ 1  3 27  3  9  7  3  2  0  0  0  0  0  0  0  0  0  0  0  0]\n","1877 469 28 63\n"]}],"source":["BATCH_SIZE = 1024\n","\n","dataset_creator = Dataset()\n","inp_lang, targ_lang, train_dataset, val_dataset = dataset_creator.call(BATCH_SIZE)\n","\n","print(len(train_dataset), len(val_dataset), len(inp_lang.word_index), len(targ_lang.word_index))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xsju8WkfGHFM"},"outputs":[],"source":["with open(input_tokenizer_retrieve, mode='wb') as data_file:\n","    pickle.dump(inp_lang, data_file, protocol=pickle.HIGHEST_PROTOCOL)\n","with open(target_tokenizer_retrieve, mode='wb') as data_file:\n","    pickle.dump(targ_lang, data_file, protocol=pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4406,"status":"ok","timestamp":1642064470524,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"_Le_OYP07wvl","outputId":"5334c8e0-bf4b-4570-8010-b3c4883e9858"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1024, 20) (1024, 20)\n"]}],"source":["example_input_batch, example_target_batch = next(iter(train_dataset))\n","print(example_input_batch.shape, example_target_batch.shape)\n","# print(example_input_batch[0])"]},{"cell_type":"markdown","metadata":{"id":"fLXYtWdZBW6a"},"source":["### Model Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1642064470526,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"uFUu1izSBVIy","outputId":"e5c11ccf-f76c-4341-fe1f-08a357563a78"},"outputs":[{"name":"stdout","output_type":"stream","text":["max_length_input, max_length_target, vocab_size_input, vocab_size_target\n","20 20 29 64\n","{'<': 1, '>': 2, 'a': 3, 'o': 4, 'e': 5, 'r': 6, 'i': 7, 'h': 8, 'n': 9, 't': 10, 's': 11, 'k': 12, 'u': 13, 'b': 14, 'l': 15, 'd': 16, 'm': 17, 'p': 18, 'c': 19, 'g': 20, 'j': 21, 'y': 22, 'w': 23, 'f': 24, 'v': 25, 'q': 26, 'z': 27, 'x': 28}\n","{'<': 1, '>': 2, 'া': 3, 'র': 4, 'ে': 5, 'ি': 6, '্': 7, 'ন': 8, 'ক': 9, 'স': 10, 'ব': 11, 'ল': 12, 'ম': 13, 'ত': 14, 'ু': 15, 'প': 16, 'ট': 17, 'দ': 18, 'ো': 19, 'জ': 20, 'গ': 21, 'ই': 22, 'হ': 23, 'শ': 24, 'ী': 25, 'য': 26, 'ড': 27, 'ভ': 28, 'য়': 29, 'ফ': 30, 'চ': 31, 'ও': 32, 'আ': 33, 'অ': 34, 'এ': 35, 'খ': 36, 'ষ': 37, 'ণ': 38, 'ং': 39, 'ধ': 40, 'থ': 41, 'উ': 42, 'ছ': 43, 'ূ': 44, 'ঁ': 45, 'ৃ': 46, 'ড়': 47, 'ঠ': 48, 'ঘ': 49, 'ঞ': 50, 'ঙ': 51, 'ৌ': 52, 'ৎ': 53, 'ৈ': 54, 'ঝ': 55, 'ঃ': 56, 'ঢ': 57, 'ঈ': 58, 'ঋ': 59, 'ঊ': 60, 'ঐ': 61, 'ঔ': 62, 'ঢ়': 63}\n"]}],"source":["vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","max_length_input = example_input_batch.shape[1]\n","max_length_output = example_target_batch.shape[1]\n","\n","steps_per_epoch = len(train_dataset)//BATCH_SIZE\n","\n","print(\"max_length_input, max_length_target, vocab_size_input, vocab_size_target\")\n","print(max_length_input, max_length_output, vocab_inp_size, vocab_tar_size)\n","\n","print(inp_lang.word_index)\n","print(targ_lang.word_index)\n","\n","embedding_dims = 32\n","rnn_units = 256\n","dense_units = 256\n","Dtype = tf.float32   #used to initialize DecoderCell Zero state\n","\n","Tx = 20\n","Ty = 20"]},{"cell_type":"markdown","metadata":{"id":"DqFYB-g1HM5o"},"source":["### Creating Encoder-Decoder Model based on tfa.seq2seq module"]},{"cell_type":"markdown","metadata":{"id":"1Swb9mvflqsQ"},"source":["### Define Model"]},{"cell_type":"markdown","metadata":{"id":"wWxPNQirBtsh"},"source":["The encoder network consists of an encoder embedding layer and a LSTM layer.\n","\n","The decoder network encompasses both decoder and attention mechanism.\n","\n","The example uses LuongAttention."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1606,"status":"ok","timestamp":1642064473497,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"CJXNQ4Vh26t9","outputId":"641dab40-a677-42e0-ab46-b23f489269cd"},"outputs":[{"data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0614d3a490>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["\n","class MyModel(tf.keras.Model):\n","    def __init__(self, input_vocab_size, output_vocab_size, embedding_dims, rnn_units):\n","        super().__init__()\n","        # Encoder\n","        self.input_vocab_size = input_vocab_size\n","        self.encoder_rnnlayer1 = tf.keras.layers.Bidirectional(\n","            tf.keras.layers.LSTM(rnn_units, return_sequences=True))\n","        self.encoder_rnnlayer2 = tf.keras.layers.LSTM(rnn_units,\n","                                                      return_sequences=True,\n","                                                      return_state=True)\n","        self.encoder_norm = tf.keras.layers.BatchNormalization()\n","\n","        # Decoder\n","        self.output_vocab_size = output_vocab_size\n","        self.decoder_embedding = tf.keras.layers.Embedding(input_dim=output_vocab_size,\n","                                                           output_dim=embedding_dims) \n","        self.dense_layer = tf.keras.layers.Dense(output_vocab_size)\n","        self.decoder_rnncell = tf.keras.layers.LSTMCell(rnn_units)\n","        # Sampler\n","        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n","        self.attention_mechanism = self.build_attention_mechanism(dense_units,None,BATCH_SIZE*[Tx])\n","        self.rnn_cell =  self.build_rnn_cell(BATCH_SIZE)\n","        self.decoder = tfa.seq2seq.BasicDecoder(self.rnn_cell, \n","                                                sampler= self.sampler,\n","                                                output_layer=self.dense_layer)\n","\n","        self.attention_mechanism.memory_initialized\n","        self.decoder_embedding_matrix = None\n","\n","\n","    def initialize_initial_state(self):\n","        self.initial_state = [\n","            tf.zeros((BATCH_SIZE, rnn_units)), tf.zeros((BATCH_SIZE, rnn_units))]\n","\n","    def build_attention_mechanism(self, units,memory, memory_sequence_length):\n","        return tfa.seq2seq.LuongAttention(units, \n","                                          memory = memory, \n","                                          memory_sequence_length=memory_sequence_length)\n","        # return tfa.seq2seq.BahdanauAttention(units, memory = memory, memory_sequence_length=memory_sequence_length)\n","\n","    # wrap decoder rnn cell  \n","    def build_rnn_cell(self, batch_size ):\n","        rnn_cell = tfa.seq2seq.AttentionWrapper(self.decoder_rnncell, self.attention_mechanism,\n","                                                attention_layer_size=dense_units)\n","        return rnn_cell\n","    \n","    def build_decoder_initial_state(self, batch_size, encoder_state,Dtype):\n","        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size = batch_size, \n","                                                                dtype = Dtype)\n","        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state) \n","        return decoder_initial_state\n","    \n","    def call(self, inputs, training=False):\n","        encoder_input, decoder_input = inputs\n","\n","        # x = self.encoder_embedding(encoder_input)\n","        x = tf.one_hot(encoder_input, depth=self.input_vocab_size)\n","        x = self.encoder_rnnlayer1(x)\n","        x = self.encoder_norm(x, training=training)\n","        a, a_tx, c_tx = self.encoder_rnnlayer2(x)\n","        \n","        decoder_emb_inp = self.decoder_embedding(decoder_input)\n","        self.attention_mechanism.setup_memory(a)\n","        decoder_initial_state = self.build_decoder_initial_state(BATCH_SIZE,\n","                                                                encoder_state=[a_tx, c_tx],\n","                                                                Dtype=tf.float32)\n","        \n","        outputs, _, _ = self.decoder(decoder_emb_inp, \n","                                     initial_state=decoder_initial_state,\n","                                     sequence_length=BATCH_SIZE*[Ty-1])\n","\n","        return outputs\n","    \n","    def evaluate(self, inputs, beam_width=3):\n","        if self.decoder_embedding_matrix is None:\n","            self.decoder_embedding_matrix = tf.train.load_variable(\n","            model_weights_path, 'decoder_embedding/embeddings/.ATTRIBUTES/VARIABLE_VALUE')\n","            print(self.decoder_embedding_matrix.shape)\n","        \n","        inference_batch_size = inputs.shape[0]\n","        # print(inputs.shape)\n","        result = ''\n","\n","        # x = self.encoder_embedding(inputs)\n","        x = tf.one_hot(inputs, depth=self.input_vocab_size)\n","        x = self.encoder_rnnlayer1(x)\n","        x = self.encoder_norm(x, training=False)\n","        enc_out, enc_h, enc_c = self.encoder_rnnlayer2(x)\n","\n","        dec_h = enc_h\n","        # dec_c = enc_c\n","\n","        start_tokens = tf.fill([inference_batch_size], targ_lang.word_index['<'])\n","        end_token = targ_lang.word_index['>']\n","\n","        enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)\n","        self.attention_mechanism.setup_memory(enc_out)\n","        # print(\"beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] :\", enc_out.shape)\n","\n","        # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n","        hidden_state = tfa.seq2seq.tile_batch([enc_h, enc_c], multiplier=beam_width)\n","        decoder_initial_state = self.rnn_cell.get_initial_state(batch_size=beam_width * inference_batch_size,\n","                                                                dtype=tf.float32)\n","        decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)\n","\n","        # Instantiate BeamSearchDecoder\n","        decoder_instance = tfa.seq2seq.BeamSearchDecoder(self.rnn_cell, \n","                                                         beam_width=beam_width, \n","                                                         output_layer=self.dense_layer)\n","        decoder_instance.maximum_iterations = tf.round(tf.reduce_max(Tx) * 2)\n","        # decoder_embedding_matrix = decoderNetwork.decoder_embedding.variables[0]\n","\n","        # The BeamSearchDecoder object's call() function takes care of everything.\n","        outputs, final_state, sequence_lengths = decoder_instance(self.decoder_embedding_matrix, \n","                                                                  start_tokens=start_tokens,\n","                                                                  end_token=end_token, \n","                                                                  initial_state=decoder_initial_state)\n","\n","        final_outputs = tf.transpose(outputs.predicted_ids, perm=(0, 2, 1))\n","        beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0, 2, 1))\n","\n","        return final_outputs.numpy(), beam_scores.numpy()\n","\n","model = MyModel(vocab_inp_size,vocab_tar_size, embedding_dims, rnn_units)\n","model.load_weights(filepath=model_weights_path)"]},{"cell_type":"markdown","metadata":{"id":"lfJTg36aCckr"},"source":["### Optimizer and Custom Loss Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yc7yp0FWEedf"},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam()"]},{"cell_type":"markdown","metadata":{"id":"00WV880hoVMc"},"source":["Here, mask is a zero-one matrix of the same size as decoder_outputs. It masks padding positions outside of the target sequence lengths with values 0."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4LrCHr3N9RWf"},"outputs":[],"source":["def get_bangla(array):\n","    bangla_list = list(map(lambda x: targ_lang.index_word[x] if x != 0 else '', array))\n","    bangla_list.append('>')\n","    return \"\".join(bangla_list[0:bangla_list.index('>')])\n","\n","def get_bangla_freq(array):\n","    bangla_list = list(map(lambda x: targ_lang.index_word[x] if x != 0 else '', array))\n","    bangla_list.append('>')\n","    bangla = \"\".join(bangla_list[0:bangla_list.index('>')])\n","    if bangla in word_frequency_dict:\n","        return [word_frequency_dict[bangla]]*len(array)\n","    return [1.0]*len(array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pT6hAEFEhVZ"},"outputs":[],"source":["sparsecategoricalcrossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n","\n","def loss_function(y_pred, y):\n","    bangla_freq = list(map(lambda x: get_bangla_freq(x), y.numpy()))\n","    bangla_freq = tf.convert_to_tensor(bangla_freq, dtype=y_pred.dtype)\n","    loss = sparsecategoricalcrossentropy(y_true=y, y_pred=y_pred)\n","    mask = tf.logical_not(tf.math.equal(y,0))   #output 0 for y=0 else output 1\n","    mask = tf.cast(mask, dtype=loss.dtype)\n","    loss = mask * loss * bangla_freq\n","    loss = tf.reduce_mean(loss)\n","    return loss\n","\n","\n","def acc_function(pred, real):\n","    pred = tf.reshape(pred, [pred.shape[0], 19, pred.shape[2]])\n","    pred = tf.argmax(pred, axis=2)\n","    pred = tf.cast(pred, dtype=real.dtype)\n","    pred = list(map(lambda x: get_bangla(x), pred.numpy()))\n","    real = list(map(lambda x: get_bangla(x), real.numpy()))\n","    accuracies = tf.equal(real, pred).numpy()\n","\n","    return accuracies.sum() / accuracies.shape[0]"]},{"cell_type":"markdown","metadata":{"id":"_f8vdgaZFAah"},"source":["### One step of training on a batch using Teacher Forcing technique"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nm3HkY9nExNB"},"outputs":[],"source":["\n","def train_step(input_batch, output_batch):\n","    #initialize loss = 0\n","    loss = 0\n","    acc = 0\n","\n","    with tf.GradientTape() as tape:\n","        # Prepare correct Decoder input & output sequence data\n","        decoder_input = output_batch[:,:-1] # ignore <end>\n","        #compare logits with timestepped +1 version of decoder_input\n","        decoder_output = output_batch[:,1:] #ignore <start>\n","\n","        outputs = model([input_batch, decoder_input], True)\n","\n","        logits = outputs.rnn_output\n","        #Calculate loss\n","\n","        loss = loss_function(logits, decoder_output)\n","        acc = acc_function(logits, decoder_output)\n","\n","\n","    #Returns the list of all layer variables / weights.\n","    variables = model.trainable_variables\n","    # differentiate loss wrt variables\n","    gradients = tape.gradient(loss, variables)\n","\n","    #grads_and_vars – List of(gradient, variable) pairs.\n","    grads_and_vars = zip(gradients,variables)\n","    optimizer.apply_gradients(grads_and_vars)\n","    return loss, acc"]},{"cell_type":"markdown","metadata":{"id":"Yr_GRb1JHp6b"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1307073,"status":"ok","timestamp":1642065862183,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"6OT9njTi-pdB","outputId":"f85b6461-9ff2-4061-fc47-0efc433e2eb2"},"outputs":[{"name":"stdout","output_type":"stream","text":["1877\n","Epoch 19 Upto Batch 1 Loss 45.4634 Accuracy 0.5596\n","Epoch 19 Upto Batch 1001 Loss 46.4020 Accuracy 0.5308\n","Epoch 19 Loss 46.8506 Accuracy 0.5289\n","Time taken for 1 epoch 652.68 sec\n","\n","Epoch 20 Upto Batch 1 Loss 44.5598 Accuracy 0.5361\n","Epoch 20 Upto Batch 1001 Loss 45.4799 Accuracy 0.5323\n","Epoch 20 Loss 45.9493 Accuracy 0.5306\n","Time taken for 1 epoch 653.97 sec\n","\n"]}],"source":["start = 18\n","EPOCHS = 2\n","\n","dataset = train_dataset\n","steps_per_epoch = len(dataset)\n","print(steps_per_epoch)\n","max_acc = .20\n","\n","for epoch in range(start, EPOCHS+start):\n","    start = time.time()\n","\n","    # encoder_initial_cell_state = initialize_initial_state()\n","    total_loss = 0\n","    total_acc = 0\n","    # print(enc_hidden[0].shape, enc_hidden[1].shape)\n","    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","        # print(inp.shape, targ.shape)\n","        batch_loss, batch_acc = train_step(inp, targ)\n","        total_loss += batch_loss\n","        total_acc += batch_acc\n","\n","        if batch % 1000 == 0:\n","            print(f'Epoch {epoch + 1} Upto Batch {batch+1} Loss {total_loss / (batch+1):.4f} Accuracy {total_acc / (batch+1):.4f}')\n","            # model.save_weights(filepath=model_weights_path)\n","            # break\n","        \n","    # break\n","\n","    acc = total_acc / steps_per_epoch\n","    if acc > max_acc:\n","        max_acc = acc\n","        # checkpoint.save(file_prefix=checkpoint_prefix)\n","        model.save_weights(filepath=model_weights_path)\n","    else:\n","        break\n","\n","    print(f'Epoch {epoch + 1} Loss {total_loss / steps_per_epoch:.4f} Accuracy {total_acc / steps_per_epoch:.4f}')\n","    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec\\n')"]},{"cell_type":"markdown","metadata":{"id":"TOJtMbjZsAuh"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQhi0irXU0Q0"},"outputs":[],"source":["# Evaluate char-level train\n","def calculate_acc(dataset):\n","    beam_width = 10\n","    correct_count = np.array([0]*4)\n","    total_count = 0\n","    steps_per_epoch = len(dataset)\n","    print(steps_per_epoch)\n","    # exit(0)\n","    start = time.time()\n","    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","        # outputs, scores = beam_evaluate(inp, beam_width=beam_width)\n","        outputs, scores = model.evaluate(inp, beam_width=beam_width)\n","        # print(targ.shape)\n","        targ = list(map(get_bangla, targ.numpy()))\n","        targ = list(map(lambda x: x.replace('<', ''), targ))\n","        # print(targ)\n","        outputs = [list(map(get_bangla, output)) for output in outputs]\n","        # print(outputs)\n","\n","        for i in range(len(targ)):\n","            if targ[i] == outputs[i][0]:\n","                correct_count[0]+=1\n","            if targ[i] in outputs[i][0:3]:\n","                correct_count[1]+=1\n","            if targ[i] in outputs[i][0:5]:\n","                correct_count[2]+=1\n","            if targ[i] in outputs[i]:\n","                correct_count[3]+=1\n","            total_count+=1\n","\n","    print(f'Total size {total_count}')\n","    print(f'Acc@1 : {((correct_count[0]/total_count))*100:.2f} %')\n","    print(f'Acc@3 : {((correct_count[1]/total_count))*100:.2f} %')\n","    print(f'Acc@5 : {((correct_count[2]/total_count))*100:.2f} %')\n","    print(f'Acc@10: {((correct_count[3]/total_count))*100:.2f} %')\n","    print(f'Time taken: {(time.time() - start):.2f} s\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"EVNMyQupng87","outputId":"96bacec2-e9ec-4cf9-e936-8fd652a9eb33"},"outputs":[{"name":"stdout","output_type":"stream","text":["1877\n","(64, 32)\n","Total size 1922048\n","Acc@1 : 54.56 %\n","Acc@3 : 69.56 %\n","Acc@5 : 75.14 %\n","Acc@10: 81.12 %\n","Time taken: 2899.34 s\n","\n","469\n","Total size 480256\n","Acc@1 : 51.93 %\n","Acc@3 : 67.70 %\n","Acc@5 : 73.66 %\n","Acc@10: 80.20 %\n","Time taken: 715.28 s\n","\n"]}],"source":["calculate_acc(train_dataset)\n","calculate_acc(val_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNGAtxO8To0G"},"outputs":[],"source":["def preprocess_word(word):\n","    word = [[char for char in ('<' + word.rstrip().lstrip() + '>')]]\n","    word = inp_lang.texts_to_sequences(word)\n","    inputs = tf.keras.preprocessing.sequence.pad_sequences(word, padding='post',\n","                                                           maxlen=20, truncating='post')\n","\n","    return tf.convert_to_tensor(inputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2Gq5sniTfX6"},"outputs":[],"source":["def predict(english_word):\n","    start = time.time()\n","    # outputs, score = beam_evaluate(preprocess_word(english_word), 5)\n","    outputs, score = model.evaluate(preprocess_word(english_word), 5)\n","    outputs = [list(map(get_bangla, output)) for output in outputs]\n","    print(outputs[0])\n","\n","    print(f'Time taken: {(time.time() - start)*1000:.2f} ms\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":644,"status":"ok","timestamp":1641908385401,"user":{"displayName":"DataLab CSE BUET","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12918222438203552441"},"user_tz":-360},"id":"umNWKk8gTfNC","outputId":"0458bb6e-e34e-4a47-dda5-7ca42ad32be0"},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 32)\n","['লে', 'লি', 'জে', 'লের', 'লেরে']\n","Time taken: 249.00 ms\n","\n"]}],"source":["predict(\"english\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["DqFYB-g1HM5o"],"name":"Encoder-Decoder-wo-embedding.ipynb","provenance":[{"file_id":"1f_vk_fPEFOP0cef3FJRaM2fBYCb3PM_-","timestamp":1642000131549},{"file_id":"1CRne9RSF7nF5KWhrvmnANA0BnTIvwh5T","timestamp":1634998819559},{"file_id":"1UxykXamm_aEkHzDEYZIVFEt5jxtYu1cn","timestamp":1624193880157},{"file_id":"https://github.com/dhirensk/ai/blob/master/English_to_French_seq2seq_tf_2_0_withAttention.ipynb","timestamp":1621616155912}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}